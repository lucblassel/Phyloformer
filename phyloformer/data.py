"""
The data module contains functions that are used to load alignment data in a format that
the Phyloformer network understands. 
"""
from itertools import combinations
import os
from typing import Dict, List, Tuple, Optional

import numpy as np
import skbio
import torch
from Bio import SeqIO
from ete3 import Tree
from torch.utils.data import Dataset
from phylodm import PhyloDM
from torch.nn.functional import one_hot

AMINO_ACIDS = np.array(list("ARNDCQEGHILKMFPSTWYVX-"))

LOOKUP = {c: i for i, c in enumerate(b"ARNDCQEGHILKMFPSTWYVX-")}
N_AAs = len(LOOKUP)

class TensorDataset(Dataset):
    """A Dataset class to train Phyloformer networks"""

    def __init__(self, directory: str, filter: Optional[List[str]] = None):
        """Instanciates a TensorDataset

        Parameters
        ----------
        directory : str
            Path to the directory containing .tensor_pair files generated by the
            `make_tensors` script.
        filter: List[str], optional
            List of tensor pair names to keep (useful if you keep training and
            validation tensors in the same directory), default is None

        Returns
        -------
        TensorDataset
            A instance of TensorDataset for training phyloformer
        """
        super(TensorDataset, self).__init__()
        self.directory = directory
        self.pairs = [
            filepath
            for filepath in os.listdir(self.directory)
            if filepath.endswith(".tensor_pair")
        ]
        if filter is not None:
            self.pairs = [id for id in self.pairs if id in filter]

    def __len__(self):
        return len(self.pairs)

    def __getitem__(self, index: int):
        pair = torch.load(os.path.join(self.directory, (self.pairs[index])))
        return pair["X"], pair["y"]


class OnTheFly(Dataset):
    def __init__(self, trees: str, alignments: str) -> None:
        super().__init__()
        self.trees = trees
        self.alns = alignments

        self.pairs = []
        for treefile in os.listdir(self.trees):
            id_ = os.path.splitext(treefile)[0]
            alnfile = f"{id_}.fasta"
            if not os.path.exists(os.path.join(self.alns, alnfile)):
                raise ValueError(
                    f"Input tree {treefile} has no corresponding alignment "
                    "{alnfile} in {self.alns}"
                    )
            self.pairs.append((
                os.path.join(self.trees, treefile),
                os.path.join(self.alns, alnfile),
            ))

    def __len__(self):
        return len(self.pairs)
    
    def __getitem__(self, index: int):
        tree, aln = self.pairs[index]
        X, ids = load_alignment(aln)
        y = []
        pdm = PhyloDM.load_from_newick_path(tree)
        dm = pdm.dm(norm=False)
        labels = pdm.taxa()
        # Generating this lookup is faster for bigger trees, 
        # however it can slow things down with small trees (e.g. 20 leaves)
        lookup = {label:index for index,label in enumerate(labels)}
        for n1, n2 in combinations(ids, 2):
            y.append(dm[lookup[n1], lookup[n2]])
        y = torch.tensor(y)


def load_alignment(path: str, device: str="cpu") -> Tuple[torch.Tensor, List[str]]:
    """
    Loads an alignment into a tensor digestible by the Phyloformer network

    Parameters
    ----------
    path : str
        Path to a fasta file containing the alignment

    Returns
    -------
    Tuple[torch.Tensor, List[str]]
        a tuple containing:
         - a tensor representing the alignment (shape 22 * seq_len * n_seq)
         - a list of ids of the sequences in the alignment
    """
    seqs = []
    ids = []
    with open(path, "rb") as infile:
        for line in infile:
            if line.startswith(b">"):
                seqs.append([])
                ids.append(line.strip()[1:].decode("utf-8"))
                continue
            for c in line.strip():
                seqs[-1].append(LOOKUP[c])

    seqs = torch.tensor(seqs).to(device)

    return one_hot(seqs, num_classes=N_AAs).permute(2, 1, 0), ids



def _read_distances_from_tree(
    path: str, normalize: bool = False
) -> Dict[Tuple[str, str], float]:
    """Reads a phylogenetic tree and returns the corresponding distance matrix

    Parameters
    ----------
    path : str
        Path to the newick file containing the tree
    normalize : bool, optional
        Wether to normalize distances or not, by default False

    Returns
    -------
    Dict[Tuple[str, str], float]
        A dictionary representing the triangular distance matrix with:
         - as keys: a tuple of the leaf ids between which the distance is computed
         - as values: the distances

    """
    tree = Tree(path)
    distances = dict()
    for i, leaf1 in enumerate(tree):
        for j, leaf2 in enumerate(tree):
            if i < j:
                distances[(leaf1.name, leaf2.name)] = leaf1.get_distance(leaf2)
    if normalize:
        diameter = max(distances.values())
        for key in distances:
            distances[key] /= diameter

    return distances


def load_tree(path: str) -> Tuple[torch.Tensor, List[Tuple[str, str]]]:
    """Loads a tree as a tensor of pairwise distances, digestible by the Phyloformer
    network

    Parameters
    ----------
    path : str
        Path to the newick file containing the tree

    Returns
    -------
    Tuple[torch.Tensor, List[Tuple[str, str]]]
        a tuple containing:
         - a tensor representing the distance matrix of the tree (shape 1\*n_pairs)
         - a list of tuples of ids indicating between which leafs the distance was
           computed

    """
    distances = _read_distances_from_tree(path)
    tensor, ids = [], []
    for pair, distance in distances.items():
        tensor.append(distance)
        ids.append(pair)

    return (torch.tensor(tensor), ids)


def load_dataset(path: str) -> List[torch.Tensor]:
    pass


def _parse_alignment(path: str) -> Dict[str, str]:
    """Parser a fasta alignment

    Parameters
    ----------
    path : str
        Path to .fasta alignment file

    Returns
    -------
    Dict[str,str]
        A dictionnary with ids as keys and sequence as values
    """
    return {record.id: str(record.seq) for record in SeqIO.parse(path, format="fasta")}


def _sequence_to_one_hot(seq: str) -> np.ndarray:
    """Encode an amino acid sequence with one-hot encoding

    Parameters
    ----------
    seq : str
        Sequence of amino acids to encode

    Returns
    -------
    np.ndarray
        Encoded sequence (shape 22\*seq_len)
    """
    return np.array([(AMINO_ACIDS == aa).astype(int) for aa in seq])


def write_dm(dm: skbio.DistanceMatrix, path: str):
    """Write a distance matrix to disk in the square Phylip matrix format

    Parameters
    ----------
    dm : skbio.DistanceMatrix
        Distance matrix to save
    path : str
        Path where to save the matrix
    """

    with open(path, "w+") as file:
        file.write(f"{len(dm.ids)}\n")
        for id, dists in zip(dm.ids, dm.data):
            line = " ".join(str(dist) for dist in dists)
            file.write(f"{id}     {line}\n")
